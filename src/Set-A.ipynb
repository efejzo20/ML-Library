{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Hackathon Set A\n",
    "\n",
    "## Machine Learning Lab, SS 24, Uni Passau\n",
    "\n",
    "### Rules:\n",
    "    \n",
    "   1. You have time from 1 pm until 5 pm to complete the exam. \n",
    "   2. Submissions must be pushed to your gitlab in a folder named `Hackathon`. Submissions are allowed until 5 pm.\n",
    "   3. Run your solutions in lines created under the individual questionnaire.\n",
    "   4. For model implementations you are permitted to use only your library in its state by the Final Deadline.\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Prepare your data [10 Points]\n",
    "\n",
    "   1. Load/Download the datasets and read them. \n",
    "   2. Analyse the data shape, targets and data characteristics. \n",
    "   3. Apply any relevant data cleaning, data filling, and if required convert to numpy vectors. \n",
    "   4. Split the datasets into `train`, `valid` and `test` folds. Use one fixed train-validation-test split consistently for all experiments.\n",
    "   5. Apply any relevant data normalisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1: [CLASSIFICATION] Iris Dataset: https://archive.ics.uci.edu/dataset/53/iris\n",
    "\n",
    "Can be Downloaded directly using curl or via sklearn as shown below:\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "```\n",
    "Dataset 2: [REGRESION] Auto MPG Dataset: https://archive.ics.uci.edu/dataset/9/auto+mpg\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\", \"car_name\"]\n",
    "auto_mpg = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values=\"?\")\n",
    "auto_mpg = auto_mpg.dropna()  # Remove rows with missing values\n",
    "\n",
    "X = auto_mpg.iloc[:, 1:-1].values  # Exclude mpg (target) and car_name (non-numeric)\n",
    "y = auto_mpg[\"mpg\"].values\n",
    "```\n",
    "\n",
    "Dataset 3: [CLUSTERING] Wine Dataset: https://archive.ics.uci.edu/dataset/109/wine\n",
    "```python\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "column_names = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame for easier inspection\n",
    "iris_df = pd.DataFrame(data=X_iris, columns=column_names)\n",
    "iris_df['target'] = y_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "target               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the target distribution\n",
    "iris_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_iris_train, X_iris_temp, y_iris_train, y_iris_temp = train_test_split(X_iris, y_iris, test_size=0.4, random_state=42)\n",
    "X_iris_valid, X_iris_test, y_iris_valid, y_iris_test = train_test_split(X_iris_temp, y_iris_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_iris_train)\n",
    "X_iris_valid = scaler.transform(X_iris_valid)\n",
    "X_iris_test = scaler.transform(X_iris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (90, 4) (90,)\n",
      "Validation set shape: (30, 4) (30,)\n",
      "Test set shape: (30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set shape:\", X_iris_train.shape, y_iris_train.shape)\n",
    "print(\"Validation set shape:\", X_iris_valid.shape, y_iris_valid.shape)\n",
    "print(\"Test set shape:\", X_iris_test.shape, y_iris_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto MPG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\", \"car_name\"]\n",
    "auto_mpg = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values=\"?\")\n",
    "auto_mpg = auto_mpg.dropna()  # Remove rows with missing values\n",
    "\n",
    "X = auto_mpg.iloc[:, 1:-1].values  # Exclude mpg (target) and car_name (non-numeric)\n",
    "y = auto_mpg[\"mpg\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_mpg = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mpg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower      float64\n",
       "weight          float64\n",
       "acceleration    float64\n",
       "model_year        int64\n",
       "origin            int64\n",
       "car_name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mpg.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model_year  origin                   car_name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.514573</td>\n",
       "      <td>5.454774</td>\n",
       "      <td>193.425879</td>\n",
       "      <td>104.469388</td>\n",
       "      <td>2970.424623</td>\n",
       "      <td>15.568090</td>\n",
       "      <td>76.010050</td>\n",
       "      <td>1.572864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.815984</td>\n",
       "      <td>1.701004</td>\n",
       "      <td>104.269838</td>\n",
       "      <td>38.491160</td>\n",
       "      <td>846.841774</td>\n",
       "      <td>2.757689</td>\n",
       "      <td>3.697627</td>\n",
       "      <td>0.802055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1613.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2223.750000</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>2803.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>3608.000000</td>\n",
       "      <td>17.175000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mpg   cylinders  displacement  horsepower       weight  \\\n",
       "count  398.000000  398.000000    398.000000  392.000000   398.000000   \n",
       "mean    23.514573    5.454774    193.425879  104.469388  2970.424623   \n",
       "std      7.815984    1.701004    104.269838   38.491160   846.841774   \n",
       "min      9.000000    3.000000     68.000000   46.000000  1613.000000   \n",
       "25%     17.500000    4.000000    104.250000   75.000000  2223.750000   \n",
       "50%     23.000000    4.000000    148.500000   93.500000  2803.500000   \n",
       "75%     29.000000    8.000000    262.000000  126.000000  3608.000000   \n",
       "max     46.600000    8.000000    455.000000  230.000000  5140.000000   \n",
       "\n",
       "       acceleration  model_year      origin  \n",
       "count    398.000000  398.000000  398.000000  \n",
       "mean      15.568090   76.010050    1.572864  \n",
       "std        2.757689    3.697627    0.802055  \n",
       "min        8.000000   70.000000    1.000000  \n",
       "25%       13.825000   73.000000    1.000000  \n",
       "50%       15.500000   76.000000    1.000000  \n",
       "75%       17.175000   79.000000    2.000000  \n",
       "max       24.800000   82.000000    3.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mpg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      6\n",
       "weight          0\n",
       "acceleration    0\n",
       "model_year      0\n",
       "origin          0\n",
       "car_name        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mpg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_mpg = auto_mpg.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_auto_mpg = auto_mpg.iloc[:, 1:-1].values \n",
    "y_auto_mpg = auto_mpg[\"mpg\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StandardScaler.StandardScaler import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_auto_mpg = scaler.fit_transform(X)\n",
    "y_auto_mpg = scaler.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (235, 7) (235,)\n",
      "Validation set shape: (78, 7) (78,)\n",
      "Test set shape: (79, 7) (79,)\n"
     ]
    }
   ],
   "source": [
    "# Split the datasets into train, validation, and test sets\n",
    "X_auto_mpg_train, X_auto_mpg_temp, y_auto_mpg_train, y_auto_mpg_temp = train_test_split(X_auto_mpg, y_auto_mpg, test_size=0.4, random_state=42)\n",
    "X_auto_mpg_valid, X_auto_mpg_test, y_auto_mpg_valid, y_auto_mpg_test = train_test_split(X_auto_mpg_temp, y_auto_mpg_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_auto_mpg_train.shape, y_auto_mpg_train.shape)\n",
    "print(\"Validation set shape:\", X_auto_mpg_valid.shape, y_auto_mpg_valid.shape)\n",
    "print(\"Test set shape:\", X_auto_mpg_test.shape, y_auto_mpg_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "column_names = wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.DataFrame(data=X_wine, columns=column_names)\n",
    "wine_df['target'] = y_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         float64\n",
       "malic_acid                      float64\n",
       "ash                             float64\n",
       "alcalinity_of_ash               float64\n",
       "magnesium                       float64\n",
       "total_phenols                   float64\n",
       "flavanoids                      float64\n",
       "nonflavanoid_phenols            float64\n",
       "proanthocyanins                 float64\n",
       "color_intensity                 float64\n",
       "hue                             float64\n",
       "od280/od315_of_diluted_wines    float64\n",
       "proline                         float64\n",
       "target                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
       "count       178.000000  178.000000                    178.000000   178.000000   \n",
       "mean          5.058090    0.957449                      2.611685   746.893258   \n",
       "std           2.318286    0.228572                      0.709990   314.907474   \n",
       "min           1.280000    0.480000                      1.270000   278.000000   \n",
       "25%           3.220000    0.782500                      1.937500   500.500000   \n",
       "50%           4.690000    0.965000                      2.780000   673.500000   \n",
       "75%           6.200000    1.120000                      3.170000   985.000000   \n",
       "max          13.000000    1.710000                      4.000000  1680.000000   \n",
       "\n",
       "           target  \n",
       "count  178.000000  \n",
       "mean     0.938202  \n",
       "std      0.775035  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      2.000000  \n",
       "max      2.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wine_train, X_wine_temp, y_wine_train, y_wine_temp = train_test_split(X_wine, y_wine, test_size=0.4, random_state=42)\n",
    "X_wine_valid, X_wine_test, y_wine_valid, y_wine_test = train_test_split(X_wine_temp, y_wine_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (106, 13) (106,)\n",
      "Validation set shape: (36, 13) (36,)\n",
      "Test set shape: (36, 13) (36,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set shape:\", X_wine_train.shape, y_wine_train.shape)\n",
    "print(\"Validation set shape:\", X_wine_valid.shape, y_wine_valid.shape)\n",
    "print(\"Test set shape:\", X_wine_test.shape, y_wine_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Apply baseline models of your choice (1 classification + 1 regression) for each of the two datasets for classification and regression respectively [20 Points]. \n",
    "\n",
    "Please note you cannot choose models expected in Task 4 as baselines.\n",
    "\n",
    "```python\n",
    "baseline = YourAlgorithm()\n",
    "baseline.fit(features_train, labels_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.linear_regression.regression_closed import ClosedFormRegression\n",
    "# Train the ClosedFormRegression model\n",
    "model = ClosedFormRegression(bias=True)\n",
    "model.fit(X_auto_mpg_train, y_auto_mpg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from models.decision_tree.tree import DecisionTree\n",
    "\n",
    "# Initialize the DecisionTree classifier\n",
    "\n",
    "decision_tree = DecisionTree(criterion='gini', max_depth=None, min_samples_split=2, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "decision_tree.fit(X_iris_train, y_iris_train)\n",
    "\n",
    "# Predict on the validation and test data\n",
    "y_iris_valid_pred = decision_tree.predict(X_iris_valid)\n",
    "y_iris_test_pred = decision_tree.predict(X_iris_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Evaluate your baseline models on test set [10 Points]: \n",
    "\n",
    "Use accuracy, precision and recall for classification, and R2 score and MAE/RMSE for regression\n",
    "\n",
    "```python\n",
    "baseline_predicted = model_baseline.predict(features_test)\n",
    "evaluate_fn(baseline_predicted, labels_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 score (Auto MPG): 0.8256138655783969\n",
      "Validation R^2 score (Auto MPG): 0.8091687750314244\n",
      "Test R^2 score (Auto MPG): 0.7799654321998786\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_score_auto_mpg = model.score(X_auto_mpg_train, y_auto_mpg_train)\n",
    "valid_score_auto_mpg = model.score(X_auto_mpg_valid, y_auto_mpg_valid)\n",
    "test_score_auto_mpg = model.score(X_auto_mpg_test, y_auto_mpg_test)\n",
    "\n",
    "print(\"Training R^2 score (Auto MPG):\", train_score_auto_mpg)\n",
    "print(\"Validation R^2 score (Auto MPG):\", valid_score_auto_mpg)\n",
    "print(\"Test R^2 score (Auto MPG):\", test_score_auto_mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE (Auto MPG): 0.3305625097262077\n",
      "Validation MAE (Auto MPG): 0.34265308240301967\n",
      "Test MAE (Auto MPG): 0.3048735030517721\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Mean Absolute Error (MAE)\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# Predictions\n",
    "y_auto_mpg_train_pred = model.predict(X_auto_mpg_train)\n",
    "y_auto_mpg_valid_pred = model.predict(X_auto_mpg_valid)\n",
    "y_auto_mpg_test_pred = model.predict(X_auto_mpg_test)\n",
    "\n",
    "# Calculate MAE\n",
    "train_mae_auto_mpg = mean_absolute_error(y_auto_mpg_train, y_auto_mpg_train_pred)\n",
    "valid_mae_auto_mpg = mean_absolute_error(y_auto_mpg_valid, y_auto_mpg_valid_pred)\n",
    "test_mae_auto_mpg = mean_absolute_error(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "\n",
    "\n",
    "print(\"Training MAE (Auto MPG):\", train_mae_auto_mpg)\n",
    "print(\"Validation MAE (Auto MPG):\", valid_mae_auto_mpg)\n",
    "print(\"Test MAE (Auto MPG):\", test_mae_auto_mpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 20.00%\n",
      "Validation Precision: 6.67%\n",
      "Validation Recall: 33.33%\n",
      "Test Accuracy: 43.33%\n",
      "Test Precision: 14.44%\n",
      "Test Recall: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, precision, and recall for validation data\n",
    "validation_accuracy = accuracy_score(y_iris_valid, y_iris_valid_pred)\n",
    "validation_precision = precision_score(y_iris_valid, y_iris_valid_pred, average='macro', zero_division=0)\n",
    "validation_recall = recall_score(y_iris_valid, y_iris_valid_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(f'Validation Accuracy: {validation_accuracy * 100:.2f}%')\n",
    "print(f'Validation Precision: {validation_precision * 100:.2f}%')\n",
    "print(f'Validation Recall: {validation_recall * 100:.2f}%')\n",
    "\n",
    "# Calculate accuracy, precision, and recall for test data\n",
    "test_accuracy = accuracy_score(y_iris_test, y_iris_test_pred)\n",
    "test_precision = precision_score(y_iris_test, y_iris_test_pred, average='macro', zero_division=0)\n",
    "test_recall = recall_score(y_iris_test, y_iris_test_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision * 100:.2f}%')\n",
    "print(f'Test Recall: {test_recall * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Apply the following methods [20 Points]:\n",
    "\n",
    "    a) Logistic Regression for classification \n",
    "    b) Artificial Neural Network for regression\n",
    "    \n",
    "Report the same metrics used for the baselines on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Logistic Regression for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.33%\n",
      "Test Precision: 42.56%\n",
      "Test Recall: 53.38%\n"
     ]
    }
   ],
   "source": [
    "from models.logistic_regression.logistic import LogisticRegression\n",
    "# Initialize the LogisticRegression classifier\n",
    "logistic_regression = LogisticRegression(learning_rate=0.01, num_iterations=1000)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "logistic_regression.fit(X_iris_train, y_iris_train)\n",
    "\n",
    "# Predict on the validation and test data\n",
    "y_iris_valid_pred = logistic_regression.predict(X_iris_valid)\n",
    "y_iris_test_pred = logistic_regression.predict(X_iris_test)\n",
    "\n",
    "# Calculate accuracy, precision, and recall for test data\n",
    "test_accuracy = accuracy_score(y_iris_test, y_iris_test_pred)\n",
    "test_precision = precision_score(y_iris_test, y_iris_test_pred, average='macro', zero_division=0)\n",
    "test_recall = recall_score(y_iris_test, y_iris_test_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision * 100:.2f}%')\n",
    "print(f'Test Recall: {test_recall * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Artificial Neural Network for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (235,235) and (1,10) not aligned: 235 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m mlp_regressor \u001b[38;5;241m=\u001b[39m MLPRegressor(hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the regressor on the training data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmlp_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_auto_mpg_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_auto_mpg_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Predict on the validation and test data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m y_auto_mpg_valid_pred \u001b[38;5;241m=\u001b[39m mlp_regressor\u001b[38;5;241m.\u001b[39mpredict(X_auto_mpg_valid)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/Documents/MLLab/ml-lab/src/models/ANN/mlp.py:210\u001b[0m, in \u001b[0;36mMLPRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, ModularLinearLayer):\n\u001b[0;32m--> 210\u001b[0m         grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m         grad \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mbackward(grad)\n",
      "File \u001b[0;32m~/Documents/MLLab/ml-lab/src/models/ANN/mlp.py:69\u001b[0m, in \u001b[0;36mModularLinearLayer.backward\u001b[0;34m(self, upstream_grad, alpha)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weight_grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bias_grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(upstream_grad, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupstream_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (235,235) and (1,10) not aligned: 235 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "from models.ANN.mlp import MLPRegressor\n",
    "\n",
    "# Initialize the MLPRegressor\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(10, 10), lr=0.0001, epochs=1000, random_state=42, activation='tanh')\n",
    "\n",
    "# Train the regressor on the training data\n",
    "mlp_regressor.fit(X_auto_mpg_train, y_auto_mpg_train)\n",
    "\n",
    "# Predict on the validation and test data\n",
    "y_auto_mpg_valid_pred = mlp_regressor.predict(X_auto_mpg_valid).flatten()\n",
    "y_auto_mpg_test_pred = mlp_regressor.predict(X_auto_mpg_test).flatten()\n",
    "\n",
    "# Calculate and print the MSE for validation and test sets\n",
    "validation_mse = np.mean((y_auto_mpg_valid_pred - y_auto_mpg_valid) ** 2)\n",
    "test_mse = np.mean((y_auto_mpg_test_pred - y_auto_mpg_test) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.14\n",
      "Test MSE: 0.10\n",
      "Validation R2 Score: 0.86\n",
      "Test R2 Score: 0.85\n",
      "Validation MAE: 0.29\n",
      "Test MAE: 0.24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Predict on the validation and test data\n",
    "y_auto_mpg_valid_pred = mlp_regressor.predict(X_auto_mpg_valid).flatten()\n",
    "y_auto_mpg_test_pred = mlp_regressor.predict(X_auto_mpg_test).flatten()\n",
    "\n",
    "# Calculate and print the MSE for validation and test sets\n",
    "validation_mse = np.mean((y_auto_mpg_valid_pred - y_auto_mpg_valid) ** 2)\n",
    "test_mse = np.mean((y_auto_mpg_test_pred - y_auto_mpg_test) ** 2)\n",
    "\n",
    "print(f'Validation MSE: {validation_mse:.2f}')\n",
    "print(f'Test MSE: {test_mse:.2f}')\n",
    "\n",
    "# Calculate and print R2 score and MAE for validation and test sets\n",
    "validation_r2 = r2_score(y_auto_mpg_valid, y_auto_mpg_valid_pred)\n",
    "test_r2 = r2_score(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "\n",
    "validation_mae = mean_absolute_error(y_auto_mpg_valid, y_auto_mpg_valid_pred)\n",
    "test_mae = mean_absolute_error(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "\n",
    "print(f'Validation R2 Score: {validation_r2:.2f}')\n",
    "print(f'Test R2 Score: {test_r2:.2f}')\n",
    "\n",
    "print(f'Validation MAE: {validation_mae:.2f}')\n",
    "print(f'Test MAE: {test_mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Hyperparameter Optimisation [20 Points]\n",
    "- For the ANN model implemented in Task 4, conduct a grid search in reasonable ranges to find an appropriate set of hyperparameters, and justify the choice by showing the best performance\n",
    "\n",
    "```python\n",
    "possible_hp_values = np.arange(1, 10, 0.1)\n",
    "best_hp_value = None\n",
    "best_f1_score = -np.infty\n",
    "for hp_value in possible_hp_values:\n",
    "    # 1. create a baseline classifier object with hp_value specified\n",
    "    current_model = YourAlgorithm(hyperparam=hp_value)\n",
    "    \n",
    "    # 2. learn the classifier on the training set\n",
    "    current_model.fit(features_train, labels_train)\n",
    "    \n",
    "    # 3. evaluate the model on the validation set\n",
    "    prediction = current_model.predict(features_valid)\n",
    "    \n",
    "    f1_score = compute_f1(labels_valid, prediction)\n",
    "    if f1_score > best_f1_score:\n",
    "        best_f1_score = f1_score\n",
    "        best_hp_value = hp_value\n",
    "\n",
    "print(\"Found hyperparameter value\", best_hp_value)\n",
    "print(\"Best f1-score on validation set\", best_f1_score)\n",
    "\n",
    "test_model = YourAlgorithm(hyperparam=best_hp_value)\n",
    "test_model.learn(features_train, labels_train)\n",
    "prediction = test_model.infer(features_test)\n",
    "test_f1_score = compute_f1(labels_test, prediction)\n",
    "print(\"F1-Score on test set\", test_f1_score)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.367268409272382\n",
      "Epoch 100, Loss: 0.12026152556965919\n",
      "Epoch 200, Loss: 0.105233459577593\n",
      "Epoch 300, Loss: 0.09705774098704045\n",
      "Epoch 400, Loss: 0.09033550177835488\n",
      "Epoch 0, Loss: 1.367268409272382\n",
      "Epoch 100, Loss: 0.4934949618511255\n",
      "Epoch 200, Loss: 0.2709454232732258\n",
      "Epoch 300, Loss: 0.19635731852067573\n",
      "Epoch 400, Loss: 0.1648227012684113\n",
      "Epoch 0, Loss: 1.076325434927391\n",
      "Epoch 100, Loss: 0.1260545885352886\n",
      "Epoch 200, Loss: 0.10184380228475204\n",
      "Epoch 300, Loss: 0.08479441675006938\n",
      "Epoch 400, Loss: 0.07422031424617748\n",
      "Epoch 0, Loss: 1.076325434927391\n",
      "Epoch 100, Loss: 0.3189733880506515\n",
      "Epoch 200, Loss: 0.19435291401567129\n",
      "Epoch 300, Loss: 0.16361000478453774\n",
      "Epoch 400, Loss: 0.1518652525743881\n",
      "Epoch 0, Loss: 0.5378370622644695\n",
      "Epoch 100, Loss: 0.08535818536911591\n",
      "Epoch 200, Loss: 0.07105450991358433\n",
      "Epoch 300, Loss: 0.06541430949462908\n",
      "Epoch 400, Loss: 0.062348452811141764\n",
      "Epoch 0, Loss: 0.5378370622644695\n",
      "Epoch 100, Loss: 0.1666448942011101\n",
      "Epoch 200, Loss: 0.13497960248289145\n",
      "Epoch 300, Loss: 0.11987918766355553\n",
      "Epoch 400, Loss: 0.11039959228779786\n",
      "Epoch 0, Loss: 1.367268409272382\n",
      "Epoch 100, Loss: 0.12026152556965919\n",
      "Epoch 200, Loss: 0.105233459577593\n",
      "Epoch 300, Loss: 0.09705774098704045\n",
      "Epoch 400, Loss: 0.09033550177835488\n",
      "Epoch 500, Loss: 0.084369724531293\n",
      "Epoch 600, Loss: 0.07925054875736626\n",
      "Epoch 700, Loss: 0.07518085725705603\n",
      "Epoch 800, Loss: 0.0721447910819376\n",
      "Epoch 900, Loss: 0.06991226205808194\n",
      "Epoch 0, Loss: 1.367268409272382\n",
      "Epoch 100, Loss: 0.4934949618511255\n",
      "Epoch 200, Loss: 0.2709454232732258\n",
      "Epoch 300, Loss: 0.19635731852067573\n",
      "Epoch 400, Loss: 0.1648227012684113\n",
      "Epoch 500, Loss: 0.14849194119073136\n",
      "Epoch 600, Loss: 0.13859721953346327\n",
      "Epoch 700, Loss: 0.13190800788572987\n",
      "Epoch 800, Loss: 0.12703618095344368\n",
      "Epoch 900, Loss: 0.12329557181208328\n",
      "Epoch 0, Loss: 1.076325434927391\n",
      "Epoch 100, Loss: 0.1260545885352886\n",
      "Epoch 200, Loss: 0.10184380228475204\n",
      "Epoch 300, Loss: 0.08479441675006938\n",
      "Epoch 400, Loss: 0.07422031424617748\n",
      "Epoch 500, Loss: 0.06781926791057619\n",
      "Epoch 600, Loss: 0.06367680994683976\n",
      "Epoch 700, Loss: 0.06075371751125024\n",
      "Epoch 800, Loss: 0.058523616286230803\n",
      "Epoch 900, Loss: 0.056719504736168415\n",
      "Epoch 0, Loss: 1.076325434927391\n",
      "Epoch 100, Loss: 0.3189733880506515\n",
      "Epoch 200, Loss: 0.19435291401567129\n",
      "Epoch 300, Loss: 0.16361000478453774\n",
      "Epoch 400, Loss: 0.1518652525743881\n",
      "Epoch 500, Loss: 0.1451192762994887\n",
      "Epoch 600, Loss: 0.14014170570598794\n",
      "Epoch 700, Loss: 0.13601050115169033\n",
      "Epoch 800, Loss: 0.13238261130447843\n",
      "Epoch 900, Loss: 0.12909210412252914\n",
      "Epoch 0, Loss: 0.5378370622644695\n",
      "Epoch 100, Loss: 0.08535818536911591\n",
      "Epoch 200, Loss: 0.07105450991358433\n",
      "Epoch 300, Loss: 0.06541430949462908\n",
      "Epoch 400, Loss: 0.062348452811141764\n",
      "Epoch 500, Loss: 0.06026979150797866\n",
      "Epoch 600, Loss: 0.05868987060172719\n",
      "Epoch 700, Loss: 0.05741610331566698\n",
      "Epoch 800, Loss: 0.05635067831780221\n",
      "Epoch 900, Loss: 0.05543513726754237\n",
      "Epoch 0, Loss: 0.5378370622644695\n",
      "Epoch 100, Loss: 0.1666448942011101\n",
      "Epoch 200, Loss: 0.13497960248289145\n",
      "Epoch 300, Loss: 0.11987918766355553\n",
      "Epoch 400, Loss: 0.11039959228779786\n",
      "Epoch 500, Loss: 0.10370350806686619\n",
      "Epoch 600, Loss: 0.09857400408177137\n",
      "Epoch 700, Loss: 0.09442427481570057\n",
      "Epoch 800, Loss: 0.09094750808048355\n",
      "Epoch 900, Loss: 0.08796938240331109\n",
      "Epoch 0, Loss: 1.0520962292061227\n",
      "Epoch 100, Loss: 0.10167133194650446\n",
      "Epoch 200, Loss: 0.08333179290599671\n",
      "Epoch 300, Loss: 0.07742297257743416\n",
      "Epoch 400, Loss: 0.07398376347130954\n",
      "Epoch 0, Loss: 1.0520962292061227\n",
      "Epoch 100, Loss: 0.41248003978742687\n",
      "Epoch 200, Loss: 0.24222125719592583\n",
      "Epoch 300, Loss: 0.1845344452120903\n",
      "Epoch 400, Loss: 0.15641390462295532\n",
      "Epoch 0, Loss: 0.8398087042533602\n",
      "Epoch 100, Loss: 0.11784028074089603\n",
      "Epoch 200, Loss: 0.09109798506907524\n",
      "Epoch 300, Loss: 0.07806354181889763\n",
      "Epoch 400, Loss: 0.06935758713391255\n",
      "Epoch 0, Loss: 0.8398087042533602\n",
      "Epoch 100, Loss: 0.5331943398721396\n",
      "Epoch 200, Loss: 0.38576067572016737\n",
      "Epoch 300, Loss: 0.288429261961856\n",
      "Epoch 400, Loss: 0.22004913563881767\n",
      "Epoch 0, Loss: 0.9169154427055504\n",
      "Epoch 100, Loss: 0.085473336095508\n",
      "Epoch 200, Loss: 0.06902092811927286\n",
      "Epoch 300, Loss: 0.06197114744642942\n",
      "Epoch 400, Loss: 0.05740087107233253\n",
      "Epoch 0, Loss: 0.9169154427055504\n",
      "Epoch 100, Loss: 0.23709429983764901\n",
      "Epoch 200, Loss: 0.17284344763881263\n",
      "Epoch 300, Loss: 0.14676384068334233\n",
      "Epoch 400, Loss: 0.1293168484437284\n",
      "Epoch 0, Loss: 1.0520962292061227\n",
      "Epoch 100, Loss: 0.10167133194650446\n",
      "Epoch 200, Loss: 0.08333179290599671\n",
      "Epoch 300, Loss: 0.07742297257743416\n",
      "Epoch 400, Loss: 0.07398376347130954\n",
      "Epoch 500, Loss: 0.07166387213934858\n",
      "Epoch 600, Loss: 0.06984178406507847\n",
      "Epoch 700, Loss: 0.06840469792805849\n",
      "Epoch 800, Loss: 0.06711041387039045\n",
      "Epoch 900, Loss: 0.06603713466495816\n",
      "Epoch 0, Loss: 1.0520962292061227\n",
      "Epoch 100, Loss: 0.41248003978742687\n",
      "Epoch 200, Loss: 0.24222125719592583\n",
      "Epoch 300, Loss: 0.1845344452120903\n",
      "Epoch 400, Loss: 0.15641390462295532\n",
      "Epoch 500, Loss: 0.13912247498730954\n",
      "Epoch 600, Loss: 0.1273301083815209\n",
      "Epoch 700, Loss: 0.11874991086986224\n",
      "Epoch 800, Loss: 0.11197125498485451\n",
      "Epoch 900, Loss: 0.10636817266691773\n",
      "Epoch 0, Loss: 0.8398087042533602\n",
      "Epoch 100, Loss: 0.11784028074089603\n",
      "Epoch 200, Loss: 0.09109798506907524\n",
      "Epoch 300, Loss: 0.07806354181889763\n",
      "Epoch 400, Loss: 0.06935758713391255\n",
      "Epoch 500, Loss: 0.0621057264593937\n",
      "Epoch 600, Loss: 0.05600538577773288\n",
      "Epoch 700, Loss: 0.052119415339730926\n",
      "Epoch 800, Loss: 0.05010362268782116\n",
      "Epoch 900, Loss: 0.04857179237506717\n",
      "Epoch 0, Loss: 0.8398087042533602\n",
      "Epoch 100, Loss: 0.5331943398721396\n",
      "Epoch 200, Loss: 0.38576067572016737\n",
      "Epoch 300, Loss: 0.288429261961856\n",
      "Epoch 400, Loss: 0.22004913563881767\n",
      "Epoch 500, Loss: 0.17645558284087212\n",
      "Epoch 600, Loss: 0.1513610018356861\n",
      "Epoch 700, Loss: 0.1372929061768912\n",
      "Epoch 800, Loss: 0.12845723414432797\n",
      "Epoch 900, Loss: 0.12244555063441424\n",
      "Epoch 0, Loss: 0.9169154427055504\n",
      "Epoch 100, Loss: 0.085473336095508\n",
      "Epoch 200, Loss: 0.06902092811927286\n",
      "Epoch 300, Loss: 0.06197114744642942\n",
      "Epoch 400, Loss: 0.05740087107233253\n",
      "Epoch 500, Loss: 0.05425467295829334\n",
      "Epoch 600, Loss: 0.051786332252963904\n",
      "Epoch 700, Loss: 0.050030976192432394\n",
      "Epoch 800, Loss: 0.048722041499281894\n",
      "Epoch 900, Loss: 0.047598326763895187\n",
      "Epoch 0, Loss: 0.9169154427055504\n",
      "Epoch 100, Loss: 0.23709429983764901\n",
      "Epoch 200, Loss: 0.17284344763881263\n",
      "Epoch 300, Loss: 0.14676384068334233\n",
      "Epoch 400, Loss: 0.1293168484437284\n",
      "Epoch 500, Loss: 0.11658203198149684\n",
      "Epoch 600, Loss: 0.1067012122169254\n",
      "Epoch 700, Loss: 0.0990867601793899\n",
      "Epoch 800, Loss: 0.09331603165452142\n",
      "Epoch 900, Loss: 0.08887278408035176\n",
      "Best Hyperparameters: {'activation': 'relu', 'epochs': 500, 'hidden_layer_sizes': (20, 10), 'lr': 0.0001}\n",
      "Validation MSE with Best Hyperparameters: 0.13\n",
      "Epoch 0, Loss: 0.9169154427055504\n",
      "Epoch 100, Loss: 0.085473336095508\n",
      "Epoch 200, Loss: 0.06902092811927286\n",
      "Epoch 300, Loss: 0.06197114744642942\n",
      "Epoch 400, Loss: 0.05740087107233253\n",
      "Test MSE: 0.10\n",
      "Test R2 Score: 0.86\n",
      "Test MAE: 0.24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the grid of hyperparameters\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (10, 10), (20, 10)],\n",
    "    'lr': [0.0001, 0.00001],\n",
    "    'epochs': [500, 1000],\n",
    "    'activation': ['tanh', 'relu']\n",
    "}\n",
    "\n",
    "# Initialize variables to track the best hyperparameters and performance\n",
    "best_params = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Perform grid search\n",
    "for params in ParameterGrid(param_grid):\n",
    "    mlp_regressor = MLPRegressor(hidden_layer_sizes=params['hidden_layer_sizes'], lr=params['lr'], epochs=params['epochs'], random_state=42, activation=params['activation'])\n",
    "    mlp_regressor.fit(X_auto_mpg_train, y_auto_mpg_train)\n",
    "    \n",
    "    # Predict on the validation data\n",
    "    y_auto_mpg_valid_pred = mlp_regressor.predict(X_auto_mpg_valid).flatten()\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_auto_mpg_valid, y_auto_mpg_valid_pred)\n",
    "    \n",
    "    # Update best hyperparameters if current model is better\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_params = params\n",
    "\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "print(f'Validation MSE with Best Hyperparameters: {best_mse:.2f}')\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_mlp_regressor = MLPRegressor(hidden_layer_sizes=best_params['hidden_layer_sizes'], lr=best_params['lr'], epochs=best_params['epochs'], random_state=42, activation=best_params['activation'])\n",
    "best_mlp_regressor.fit(X_auto_mpg_train, y_auto_mpg_train)\n",
    "y_auto_mpg_test_pred = best_mlp_regressor.predict(X_auto_mpg_test).flatten()\n",
    "test_mse = mean_squared_error(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "test_r2 = r2_score(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "test_mae = mean_absolute_error(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "\n",
    "print(f'Test MSE: {test_mse:.2f}')\n",
    "print(f'Test R2 Score: {test_r2:.2f}')\n",
    "print(f'Test MAE: {test_mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'activation': 'relu', 'epochs': 500, 'hidden_layer_sizes': (20, 10), 'lr': 0.0001}\n",
      "Validation MSE with Best Hyperparameters: 0.13\n",
      "Epoch 0, Loss: 0.9169154427055504\n",
      "Epoch 100, Loss: 0.085473336095508\n",
      "Epoch 200, Loss: 0.06902092811927286\n",
      "Epoch 300, Loss: 0.06197114744642942\n",
      "Epoch 400, Loss: 0.05740087107233253\n",
      "Test MSE: 0.10\n",
      "Test R2 Score: 0.86\n",
      "Test MAE: 0.24\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Hyperparameters: {best_params}')\n",
    "print(f'Validation MSE with Best Hyperparameters: {best_mse:.2f}')\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_mlp_regressor = MLPRegressor(hidden_layer_sizes=best_params['hidden_layer_sizes'], lr=best_params['lr'], epochs=best_params['epochs'], random_state=42, activation=best_params['activation'])\n",
    "best_mlp_regressor.fit(X_auto_mpg_train, y_auto_mpg_train)\n",
    "y_auto_mpg_test_pred = best_mlp_regressor.predict(X_auto_mpg_test).flatten()\n",
    "test_mse = mean_squared_error(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "test_r2 = r2_score(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "test_mae = mean_absolute_error(y_auto_mpg_test, y_auto_mpg_test_pred)\n",
    "\n",
    "print(f'Test MSE: {test_mse:.2f}')\n",
    "print(f'Test R2 Score: {test_r2:.2f}')\n",
    "print(f'Test MAE: {test_mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Cross-Validation [10 Points]\n",
    "\n",
    "- Over multiple runs $r \\geq 5, r\\in\\mathbb{N}$  randomly shuffle your training data.\n",
    "- Split it into a train-test, e.g. 90% of the data is for training, 10% for testing.\n",
    "- Report the mean and standard deviation of the error/accuracy of your models over the multiple runs.\n",
    "- Plot a boxplot of the stability of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 326.36306417630726\n",
      "Epoch 100, Loss: 11.76367297788582\n",
      "Epoch 200, Loss: 7.135723875643678\n",
      "Epoch 300, Loss: 5.088876848304974\n",
      "Epoch 400, Loss: 4.413212286439414\n",
      "Epoch 0, Loss: 326.3081780403715\n",
      "Epoch 100, Loss: 13.532218729640203\n",
      "Epoch 200, Loss: 6.476990020115173\n",
      "Epoch 300, Loss: 5.5488876202294515\n",
      "Epoch 400, Loss: 5.158870503618989\n",
      "Epoch 0, Loss: 323.88944281775343\n",
      "Epoch 100, Loss: 30.277675268112127\n",
      "Epoch 200, Loss: 29.802287482768325\n",
      "Epoch 300, Loss: 29.79403056569356\n",
      "Epoch 400, Loss: 207.23227462529394\n",
      "Epoch 0, Loss: 329.9398348230189\n",
      "Epoch 100, Loss: 30.55190706969279\n",
      "Epoch 200, Loss: 30.205671476163822\n",
      "Epoch 300, Loss: 30.195035206909825\n",
      "Epoch 400, Loss: 30.08343385432266\n",
      "Epoch 0, Loss: 326.30833269141635\n",
      "Epoch 100, Loss: 30.17375235005773\n",
      "Epoch 200, Loss: 29.83924078617929\n",
      "Epoch 300, Loss: 29.83898263738861\n",
      "Epoch 400, Loss: 29.83898243817039\n",
      "Mean MSE: 38.11, Std MSE: 27.24\n",
      "Mean R2 Score: 0.43, Std R2 Score: 0.37\n",
      "Mean MAE: 4.71, Std MAE: 2.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Auto MPG dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "column_names = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\", \"origin\", \"car_name\"]\n",
    "auto_mpg = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values=\"?\")\n",
    "\n",
    "# Remove rows with missing values\n",
    "auto_mpg = auto_mpg.dropna()\n",
    "\n",
    "# Extract features and target variable\n",
    "X_auto_mpg = auto_mpg.iloc[:, 1:-1].values  # Exclude mpg (target) and car_name (non-numeric)\n",
    "y_auto_mpg = auto_mpg[\"mpg\"].values\n",
    "\n",
    "# Define the parameters for cross-validation\n",
    "n_runs = 5\n",
    "test_size = 0.1\n",
    "random_state = 42\n",
    "\n",
    "# Initialize lists to store the performance metrics for each run\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for run in range(n_runs):\n",
    "    # Shuffle and split the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_auto_mpg, y_auto_mpg, test_size=test_size, random_state=random_state + run)\n",
    "    \n",
    "    # Apply data normalization\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize and train the MLPRegressor\n",
    "    mlp_regressor = MLPRegressor(hidden_layer_sizes=(20, 10), lr=0.0001, epochs=500, random_state=random_state, activation='relu')\n",
    "    mlp_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_test_pred = mlp_regressor.predict(X_test).flatten()\n",
    "\n",
    "    # Calculate and store the performance metrics\n",
    "    mse_scores.append(mean_squared_error(y_test, y_test_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_test_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "# Calculate mean and standard deviation of the metrics\n",
    "mean_mse = np.mean(mse_scores)\n",
    "std_mse = np.std(mse_scores)\n",
    "\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "std_r2 = np.std(r2_scores)\n",
    "\n",
    "mean_mae = np.mean(mae_scores)\n",
    "std_mae = np.std(mae_scores)\n",
    "\n",
    "print(f'Mean MSE: {mean_mse:.2f}, Std MSE: {std_mse:.2f}')\n",
    "print(f'Mean R2 Score: {mean_r2:.2f}, Std R2 Score: {std_r2:.2f}')\n",
    "print(f'Mean MAE: {mean_mae:.2f}, Std MAE: {std_mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Cluster the clustering dataset using K-Means clustering [10 points]\n",
    "\n",
    "Determine the optimal number of clusters using the elbow method, and plot the relevant curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/MLLab/ml-lab/src/models/k_means/clustering.py:70: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(C)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.k_means.clustering import KMeans\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_wine_train_scaled = scaler.fit_transform(X_wine_train)\n",
    "X_wine_valid_scaled = scaler.transform(X_wine_valid)\n",
    "X_wine_test_scaled = scaler.transform(X_wine_test)\n",
    "\n",
    "# Determine the optimal number of clusters using the elbow method\n",
    "sse = []\n",
    "list_k = list(range(1, 11))\n",
    "\n",
    "for k in list_k:\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=100, tol=1e-4, random_state=42)\n",
    "    kmeans.fit(X_wine_train_scaled)\n",
    "    \n",
    "    # Compute clusters and calculate the sum of squared errors\n",
    "    clusters = kmeans.compute_clusters(X_wine_train_scaled, kmeans.centroids_)\n",
    "    centroids = kmeans.centroids_\n",
    "    distances = np.min(kmeans.euclidean_distance(X_wine_train_scaled, centroids), axis=1)\n",
    "    sse.append(np.sum(distances**2))\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Sum of Squared Errors (SSE)')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of clusters (k) is 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS Task: Apply the CNN on the classification problem and report the relevant metrics [20 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer <models.DL.mlp.ConvLayer object at 0x7f22294fff40> output shape: (2, 2, 4)\n",
      "Layer <models.DL.mlp.PoolingLayer object at 0x7f21fa98fa60> output shape: (1, 1, 4)\n",
      "Layer <models.DL.mlp.ConvLayer object at 0x7f21fa98fc10> output shape: (1, 1, 8)\n",
      "Layer <models.DL.mlp.PoolingLayer object at 0x7f21fa98f460> output shape: (0, 0, 8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (5,32) and (0,3) not aligned: 32 (dim 1) != 0 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Use the modified fit method\u001b[39;00m\n\u001b[1;32m     86\u001b[0m cnn\u001b[38;5;241m.\u001b[39mfit \u001b[38;5;241m=\u001b[39m fit_with_shape_logging\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(cnn, CNNClassifier)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[1;32m     90\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[16], line 56\u001b[0m, in \u001b[0;36mfit_with_shape_logging\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     53\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m X[batch_idx], y[batch_idx]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForward pass output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate loss and its gradient\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MLLab/ml-lab/src/models/DL/mlp.py:384\u001b[0m, in \u001b[0;36mCNNClassifier._forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    382\u001b[0m     X \u001b[38;5;241m=\u001b[39m layer(X)\n\u001b[1;32m    383\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(X, (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax_layer_(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_layer_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/MLLab/ml-lab/src/models/DL/mlp.py:54\u001b[0m, in \u001b[0;36mModularLinearLayer.__call__\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03mForward pass of the layer\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_input \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (5,32) and (0,3) not aligned: 32 (dim 1) != 0 (dim 0)"
     ]
    }
   ],
   "source": [
    "from models.DL.mlp import CNNClassifier, ConvLayer, ReLULayer, PoolingLayer,ModularLinearLayer,SoftmaxLayer\n",
    "# Load the Iris dataset\n",
    "# Load the Iris dataset\n",
    "# Load the Iris dataset\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape to (batch_size, 2, 2, 1)\n",
    "X = X.reshape(-1, 2, 2, 1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Initialize the CNN layers\n",
    "rng = np.random.RandomState(42)\n",
    "layers = [\n",
    "    ConvLayer(1, 4, (2, 2), rng=rng),\n",
    "    ReLULayer(),\n",
    "    PoolingLayer((2, 2), stride=(1, 1)),  # Pooling with (1, 1) to keep the shape since input is small\n",
    "    ConvLayer(4, 8, (2, 2), rng=rng),\n",
    "    ReLULayer(),\n",
    "    PoolingLayer((2, 2), stride=(1, 1))\n",
    "]\n",
    "\n",
    "# Initialize the CNNClassifier\n",
    "cnn = CNNClassifier(layers, random_state=42, input_shape=(2, 2, 1), epochs=100, lr=0.01, batch_size=5)\n",
    "\n",
    "\n",
    "cnn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = cnn.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
